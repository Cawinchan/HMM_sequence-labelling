{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "folder_dir = \"RU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE_emission_parameters(train_dir = \"data/ES/train\"):\n",
    "    ''' Calculates the emission parameters by count(y->x)/count(y)\n",
    "    \n",
    "    :param train_dir: our train file path to either ES or RU\n",
    "    :type train_dir: str\n",
    "\n",
    "    :return: count_y_dict, Count(y), keys are word '!', value MLE\n",
    "    :rtype: dict\n",
    "\n",
    "    :return: count_y_to_x_dict, Count(y->x), keys are tuples of word and label ('!', 'O'), value MLE\n",
    "    :rtype: dict    \n",
    "\n",
    "    :return: emission_dict, Count(y->x)/Count(y), keys are tuples of word and label ('!', 'O'), value MLE\n",
    "    :rtype: dict\n",
    "    \n",
    "    '''\n",
    "    count_y_dict = {}\n",
    "    count_y_to_x_dict = {}\n",
    "    emission_dict = {}\n",
    "\n",
    "    with open(train_dir, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # Parse each line\n",
    "            if len(line.split(\" \")) == 2:\n",
    "                word, label = line.replace(\"\\n\",\"\").split(\" \")\n",
    "            else:\n",
    "                # skip lines with space \n",
    "                continue\n",
    "            if label in count_y_dict:\n",
    "                count_y_dict[label] = count_y_dict.get(label) + 1\n",
    "            else:\n",
    "                count_y_dict[label] = 1\n",
    "            if (word,label) in count_y_to_x_dict:\n",
    "                count_y_to_x_dict[(word,label)] = count_y_to_x_dict.get((word,label)) + 1\n",
    "            else:\n",
    "                count_y_to_x_dict[(word,label)] = 1\n",
    "    print(\"count(y): \\n\", count_y_dict, \"\\n\")\n",
    "    print(\"count(y->x): \\n\",list(count_y_to_x_dict.items())[0:5], len(count_y_to_x_dict), \"\\n\")\n",
    "    # Calculate our emission\n",
    "    for key, value in count_y_to_x_dict.items(): # Default is iterate keys()\n",
    "        word = key[0]\n",
    "        label = key[1]\n",
    "        prob =  value / count_y_dict.get(label)\n",
    "        emission_dict[key] = np.where(prob != 0, np.log(prob), float(\"-inf\"))\n",
    "    print(\"MLE: \\n\",list(emission_dict.items())[0:5],len(emission_dict) ,\"\\n\")\n",
    "\n",
    "    return count_y_dict, count_y_to_x_dict, emission_dict\n",
    "\n",
    "def new_MLE_emission_parameters_with_unknown(count_y_dict, count_y_to_x_dict, emission_dict, k=1):\n",
    "    ''' Adds the unknown_word_token to our dictionary and finds our new emission paramters \n",
    "\n",
    "    :param count_y_dict: count y dictionary\n",
    "    :type count_y_dict: dict\n",
    "\n",
    "    :param count_y_to_x_dict: count y -> x dictionary\n",
    "    :type count_y_to_x_dict: dict\n",
    "    \n",
    "    :param emission_dict: Emission dictionary\n",
    "    :type emission_dict: dict\n",
    "\n",
    "    :param k: we assume we have observed that there are k occurrences of such an event.\n",
    "    :type k: int\n",
    "\n",
    "    :return: emission_plus_unknown_dict, keys are tuple of word and label ('!', 'O'), value MLE\n",
    "    :rtype: dict\n",
    "    \n",
    "    '''\n",
    "    # Calculate our new emission\n",
    "    for key, value in count_y_to_x_dict.items(): # Default is iterate keys()\n",
    "        label = key[1]\n",
    "        prob =  value / (count_y_dict.get(label) + k)\n",
    "        emission_dict[key] = np.where(prob != 0, np.log(prob), float(\"-inf\"))\n",
    "\n",
    "    print(\"#UNK# values:\")\n",
    "    for key in count_y_dict:\n",
    "        prob = k / (count_y_dict.get(key) + k)\n",
    "        emission_dict[(\"#UNK#\",key)] = np.where(prob != 0, np.log(prob), float(\"-inf\"))\n",
    "        print((\"#UNK#\",key),emission_dict.get((\"#UNK#\",key)))\n",
    "    return emission_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Emission Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(y): \n",
      " {'O': 44638, 'B-positive': 2118, 'B-neutral': 222, 'I-positive': 691, 'B-negative': 442, 'I-negative': 124, 'I-neutral': 70} \n",
      "\n",
      "count(y->x): \n",
      " [(('А', 'O'), 51), (('жаль', 'O'), 6), (('...', 'O'), 194), (('новое', 'O'), 6), (('место', 'B-positive'), 57)] 9240 \n",
      "\n",
      "MLE: \n",
      " [(('А', 'O'), array(-6.77451516)), (('жаль', 'O'), array(-8.91458132)), (('...', 'O'), array(-5.43848263)), (('новое', 'O'), array(-8.91458132)), (('место', 'B-positive'), array(-3.61517626))] 9240 \n",
      "\n",
      "#UNK# values:\n",
      "('#UNK#', 'O') -10.706363195370585\n",
      "('#UNK#', 'B-positive') -7.658699558268299\n",
      "('#UNK#', 'B-neutral') -5.407171771460119\n",
      "('#UNK#', 'I-positive') -6.539585955617669\n",
      "('#UNK#', 'B-negative') -6.093569770045136\n",
      "('#UNK#', 'I-negative') -4.8283137373023015\n",
      "('#UNK#', 'I-neutral') -4.2626798770413155\n"
     ]
    }
   ],
   "source": [
    "train_dir = f\"data/{folder_dir}/train\"\n",
    "\n",
    "count_y_dict, count_y_to_x_dict, emission_dict = MLE_emission_parameters(train_dir)\n",
    "emission_dict = new_MLE_emission_parameters_with_unknown(count_y_dict, count_y_to_x_dict, emission_dict, k=1)\n",
    "# print(emission_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting our sequence labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(emission_dict, test_dir=\"data/ES/dev.in\", output_dir=\"data/ES/dev.p1.out\"):\n",
    "    ''' Finds our predicted_y with our emission_dict\n",
    "    \n",
    "    :param test_dir: our test file in either ES or RU\n",
    "    :type test_dir: str\n",
    "\n",
    "    :param output_dir: our output file for either ES or RU\n",
    "    :type test_dir: str\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    emission_word_set = set(i[0] for i in list(emission_dict.keys()))\n",
    "\n",
    "    emission_label_lst = list(set(i[1] for i in list(emission_dict.keys())))\n",
    "\n",
    "    with open(output_dir,'w', encoding=\"utf-8\") as f:\n",
    "        with open(test_dir,'r',encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                if len(line.replace(\"\\n\",\"\")) > 0:\n",
    "                    word = line.replace(\"\\n\",\"\")\n",
    "                else:\n",
    "                    f.write(\"\\n\")                    \n",
    "                    continue\n",
    "                if word not in emission_word_set: # If there is no such word in emission set word as unknown\n",
    "                    word = \"#UNK#\"\n",
    "\n",
    "                label_arr = np.zeros((len(emission_label_lst)))\n",
    "                for idx, label in enumerate(emission_label_lst):\n",
    "                    if emission_dict.get((word,label)):\n",
    "                        label_arr[idx] = emission_dict.get((word,label))\n",
    "                    else:\n",
    "                        label_arr[idx] = float(\"-inf\")\n",
    "                predicted_y_idx = np.argmax(label_arr,axis=0)\n",
    "                predicted_y = emission_label_lst[predicted_y_idx] # Convert argmax index to predicted name\n",
    "                f.write(f\"{word} {predicted_y}\\n\") # Write in our original word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = f\"data/{folder_dir}/dev.in\"\n",
    "output_dir = f\"data/{folder_dir}/dev.p1.out\"\n",
    "\n",
    "predict_y(emission_dict,test_dir,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Transition Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  MLE_transition_parameters(train_dir = \"data/ES/train\"):\n",
    "    ''' Calculates the emission parameters by count(y->x)/count(y)\n",
    "    \n",
    "    :param train_dir: our train file path to either ES or RU\n",
    "    :type train_dir: str\n",
    "\n",
    "    :return: count_y_dict, Count(y), keys are word '!', value MLE\n",
    "    :rtype: dict\n",
    "\n",
    "    :return: count_y_to_y_dict, Count(y->x), keys are tuples of word and label ('!', 'O'), value MLE\n",
    "    :rtype: dict    \n",
    "\n",
    "    :return: emission_dict, Count(y->x)/Count(y), keys are tuples of word and label ('!', 'O'), value MLE\n",
    "    :rtype: dict\n",
    "\n",
    "    '''\n",
    "    count_y_dict = {}\n",
    "    count_y_to_y_dict = {}\n",
    "    transition_dict = {}\n",
    "    prev_label = \"\"\n",
    "    count = 0\n",
    "    othercount = 0\n",
    "\n",
    "    with open(train_dir, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # Parse each line\n",
    "            if len(line.split(\" \")) == 2:\n",
    "                word, label = line.replace(\"\\n\",\"\").split(\" \")\n",
    "            else:\n",
    "                word = ''\n",
    "                label = ''\n",
    "            if label == '' and prev_label != '':\n",
    "                count_y_dict[\"STOP\"] = count_y_dict.get(\"STOP\") + 1 if count_y_dict.get(\"STOP\") else 1\n",
    "            elif label !='':\n",
    "                if prev_label == '':\n",
    "                    count_y_dict[\"START\"] = count_y_dict.get(\"START\") + 1 if count_y_dict.get(\"START\") else 1\n",
    "                if label in count_y_dict:\n",
    "                    count_y_dict[label] = count_y_dict.get(label)+1\n",
    "                else:\n",
    "                    count_y_dict[label] = 1\n",
    "            if prev_label == '' and label != '':\n",
    "                if (\"START\", label) in count_y_to_y_dict:\n",
    "                    count_y_to_y_dict[(\"START\", label)] = count_y_to_y_dict.get((\"START\", label)) + 1\n",
    "                else:\n",
    "                    count_y_to_y_dict[(\"START\", label)] = 1\n",
    "            elif label == '' and prev_label != '':\n",
    "                if (prev_label, \"STOP\") in count_y_to_y_dict:\n",
    "                    count_y_to_y_dict[(prev_label, \"STOP\")] = count_y_to_y_dict.get((prev_label, \"STOP\")) + 1\n",
    "                else:\n",
    "                    count_y_to_y_dict[(prev_label, \"STOP\")] = 1\n",
    "            elif label != '' and prev_label != '':\n",
    "                if (prev_label, label) in count_y_to_y_dict:\n",
    "                    count_y_to_y_dict[(prev_label, label)] = count_y_to_y_dict.get((prev_label, label)) + 1\n",
    "                else:\n",
    "                    count_y_to_y_dict[(prev_label, label)] = 1\n",
    "            prev_label = label\n",
    "    print(\"count(y): \\n\", count_y_dict, \"\\n\")\n",
    "    print(\"count(y->x): \\n\",list(count_y_to_y_dict.items()), len(count_y_to_y_dict), \"\\n\")\n",
    "    # Calculate our transition\n",
    "    for key, value in count_y_to_y_dict.items(): # Default is iterate keys()\n",
    "        prev_label = key[0]\n",
    "        label = key[1]\n",
    "        prob =  value / count_y_dict.get(prev_label)\n",
    "        transition_dict[key] = np.where(prob != 0, np.log(prob), float(\"-inf\"))\n",
    "    print(\"MLE: \\n\",list(transition_dict.items()), len(transition_dict) ,\"\\n\")\n",
    "\n",
    "    return count_y_dict, count_y_to_y_dict, transition_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(y): \n",
      " {'START': 3405, 'O': 44638, 'B-positive': 2118, 'STOP': 3405, 'B-neutral': 222, 'I-positive': 691, 'B-negative': 442, 'I-negative': 124, 'I-neutral': 70} \n",
      "\n",
      "count(y->x): \n",
      " [(('START', 'O'), 2890), (('O', 'O'), 38972), (('O', 'B-positive'), 1736), (('B-positive', 'O'), 1717), (('O', 'STOP'), 3402), (('START', 'B-positive'), 379), (('O', 'B-neutral'), 144), (('B-neutral', 'O'), 190), (('B-positive', 'I-positive'), 398), (('I-positive', 'O'), 396), (('I-positive', 'I-positive'), 293), (('O', 'B-negative'), 384), (('B-negative', 'O'), 367), (('START', 'B-negative'), 58), (('START', 'B-neutral'), 78), (('B-negative', 'I-negative'), 75), (('I-negative', 'I-negative'), 49), (('I-negative', 'O'), 74), (('B-neutral', 'I-neutral'), 32), (('I-neutral', 'I-neutral'), 38), (('I-neutral', 'O'), 32), (('B-positive', 'B-positive'), 2), (('I-negative', 'STOP'), 1), (('I-positive', 'B-positive'), 1), (('I-positive', 'STOP'), 1), (('B-positive', 'STOP'), 1)] 26 \n",
      "\n",
      "MLE: \n",
      " [(('START', 'O'), array(-0.16398844)), (('O', 'O'), array(-0.13574207)), (('O', 'B-positive'), array(-3.2470019)), (('B-positive', 'O'), array(-0.20989367)), (('O', 'STOP'), array(-2.57422202)), (('START', 'B-positive'), array(-2.19546401)), (('O', 'B-neutral'), array(-5.73652749)), (('B-neutral', 'O'), array(-0.15565331)), (('B-positive', 'I-positive'), array(-1.67177552)), (('I-positive', 'O'), array(-0.55672561)), (('I-positive', 'I-positive'), array(-0.85796721)), (('O', 'B-negative'), array(-4.75569824)), (('B-negative', 'O'), array(-0.18594803)), (('START', 'B-negative'), array(-4.07255721)), (('START', 'B-neutral'), array(-3.77629139)), (('B-negative', 'I-negative'), array(-1.77382177)), (('I-negative', 'I-negative'), array(-0.92846127)), (('I-negative', 'O'), array(-0.51621647)), (('B-neutral', 'I-neutral'), array(-1.93694148)), (('I-neutral', 'I-neutral'), array(-0.61090908)), (('I-neutral', 'O'), array(-0.78275934)), (('B-positive', 'B-positive'), array(-6.96508035)), (('I-negative', 'STOP'), array(-4.82028157)), (('I-positive', 'B-positive'), array(-6.53813982)), (('I-positive', 'STOP'), array(-6.53813982)), (('B-positive', 'STOP'), array(-7.65822753))] 26 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dir = f\"data/{folder_dir}/train\"\n",
    "\n",
    "count_y_dict, count_y_to_y_dict, transition_dict = MLE_transition_parameters(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(emission_dict, transition_dict, test_dir, output_dir = \"data/ES/dev.p2.out\"):\n",
    "    test_array = []\n",
    "    viterbi_array = [{\"word\": \"\", 'O': 0, \"START\": (1, ''), 'STOP': 0, 'B-positive': 0, 'B-negative': 0, 'B-neutral': 0, 'I-positive': 0, 'I-negative': 0, 'I-neutral': 0}]\n",
    "    labels = ['O', 'START', 'STOP', 'B-positive', 'B-negative', 'B-neutral', 'I-positive', 'I-negative', 'I-neutral']\n",
    "\n",
    "    emission_word_set = set(i[0] for i in list(emission_dict.keys()))\n",
    "\n",
    "    with open(test_dir, 'r',encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            test_array += [line.replace(\"\\n\",\"\")]\n",
    "\n",
    "    count = 1\n",
    "    for word in test_array:\n",
    "        temp_dict = {'word': word}\n",
    "        if word == '':\n",
    "            temp_list = []\n",
    "            for prev_y in labels:\n",
    "                if viterbi_array[count - 1].get(prev_y) != 0:\n",
    "                    if transition_dict.get((prev_y, \"STOP\")):\n",
    "                        temp_list.append(np.longdouble(viterbi_array[count - 1].get(prev_y)[0] * transition_dict.get((prev_y, \"STOP\"))))\n",
    "                    else:\n",
    "                        temp_list.append(0)\n",
    "                else:\n",
    "                    temp_list.append(0)\n",
    "\n",
    "            max_index = np.argmax(temp_list)\n",
    "            for y in labels:\n",
    "                if y == \"STOP\":\n",
    "                    temp_dict[y] = (temp_list[max_index], labels[max_index])\n",
    "                elif y == \"START\":\n",
    "                    temp_dict[y] = (1, '')\n",
    "                else:\n",
    "                    temp_dict[y] = 0\n",
    "            viterbi_array.append(temp_dict)\n",
    "        else:\n",
    "            if word not in emission_word_set:\n",
    "                word = \"#UNK#\"\n",
    "            for t in labels:\n",
    "                if emission_dict.get((word, t)):\n",
    "                    temp_list = []\n",
    "                    for prev_y in labels:\n",
    "                        if viterbi_array[count - 1].get(prev_y) != 0:\n",
    "                            # if count ==  5328:\n",
    "                            #     print(emission_dict.get((word, t)))\n",
    "                            #     print(transition_dict.get((prev_y, t)))\n",
    "                            if transition_dict.get((prev_y, t)):\n",
    "                                temp_list.append(viterbi_array[count - 1].get(prev_y)[0] * transition_dict.get((prev_y, t)) * emission_dict.get((word, t)))\n",
    "                            else:\n",
    "                                temp_list.append(0)\n",
    "                        else:\n",
    "                            temp_list.append(0)\n",
    "                    max_index = np.argmax(temp_list)\n",
    "                    temp_dict[t] = (temp_list[max_index], labels[max_index])\n",
    "                else:\n",
    "                    temp_dict[t] = 0\n",
    "                \n",
    "            viterbi_array.append(temp_dict)\n",
    "        count += 1\n",
    "\n",
    "    result_array = [\"\"]*len(viterbi_array)\n",
    "    for i in range(len(viterbi_array) - 1, 0, -1):\n",
    "        if i == len(viterbi_array) - 1:\n",
    "            result_array[i] = viterbi_array[i].get(\"word\")\n",
    "        tmp_list = []\n",
    "        if viterbi_array[i].get('word') == '':\n",
    "            result_array[i] = ''\n",
    "            prev_label = viterbi_array[i].get('STOP')[1]\n",
    "        else:\n",
    "            result_array[i] = viterbi_array[i].get(\"word\") + \" \" + prev_label\n",
    "            try:\n",
    "                prev_label = viterbi_array[i].get(prev_label)[1]\n",
    "            except:\n",
    "                prev_label = 'O'\n",
    "\n",
    "    with open(output_dir,'w', encoding=\"utf-8\") as f:\n",
    "        for i in result_array[1:]:\n",
    "            f.write(i + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = f\"data/{folder_dir}/dev.in\"\n",
    "output_dir = f\"data/{folder_dir}/dev.p2.out\"\n",
    "viterbi(emission_dict, transition_dict, test_dir, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6812ffed06b5cffa901a574e9a3e59a1818ab1760ef7e635753d5703565f15d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('money': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
